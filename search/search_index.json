{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\ud83d\udcda My Learning Journal","text":"<p>Welcome to my personal learning space! This repository serves as a digital garden where I document my journey, track my progress, and store notes on everything I learn. I would like to refer the ever important verse, \"Every Journey of thousand miles starts with a single step.\" And keep these phrases close to your heart.</p> <p>Enjoy each step, be aware and intentional. Rushing yields no worth.  Patience, and relentless effort until everthing moves frictionless.  The story you tell yourself becomes the reality you live in.</p>"},{"location":"#important-links","title":"Important links","text":"<p>https://github.com/arunjeevaraj/Learning_journal</p>"},{"location":"#current-focus","title":"\ud83d\ude80 Current Focus","text":"<ul> <li>[ ] Python (Fixed point implementation of DSP)</li> <li>[ ] DSP (DSP algorithms and understanding)</li> <li>[ ] Scripting (TCL, Bash and other automation scripts. )</li> <li>[ ] FPGA-implementation (FPGA design sources and implementation )</li> <li>[ ] ASIC-implementation (ASIC design sources and implementation )</li> <li>[ ] Books (References to books read, and status. )</li> </ul>"},{"location":"#directory-structure","title":"\ud83d\udcc2 Directory Structure","text":"<ul> <li><code>/python</code> - Exercises, scripts, and notes in Python targeting DSP applications.</li> <li><code>/DSP</code> - block diagrams, details and documentation.</li> <li><code>/Scripting</code> - FPGA/ASIC scripts, automations etc.</li> <li><code>/FPGA-implementation</code> - FPGA design sources and implementation .</li> <li><code>/ASIC-implementation</code> - ASIC design sources and implementation .</li> <li><code>/til</code> - Today I Learned: Short, daily bite-sized notes.</li> <li><code>/books</code> - document the books read, plan to read and so forth.</li> <li><code>/resources</code> - links, and courses I'm following.</li> </ul>"},{"location":"#contribution-goal","title":"\ud83d\udcc8 Contribution Goal","text":"<p>I aim to commit at least 3 times a week to keep the momentum going!</p>"},{"location":"#connect-with-me","title":"\ud83d\udd17 Connect with me","text":"<ul> <li>GitHub: @arunjeevaraj</li> </ul>"},{"location":"DSP/algorithms/dft_vs_fft/","title":"DFT vs. FFT: Complexity and Implementation","text":""},{"location":"DSP/algorithms/dft_vs_fft/#a-personal-remark-about-this-topic","title":"A personal remark about this topic","text":"<p>This is one algorithm, which took forever for me to understand and grasp and even now I dont dare to claim to understand it fully. From my batchelors as a theory topic and to double down into it's depth during image processing electives by performing 2D FFT.  I knew about the maths and how to do it, I knew about the spectrum analysis and to make use of the data. But conceptually to digest it further, it took me more time. The orthogonal basis vectors and vector space analysis, opened up a different perspective. It gave me the idea about how the Maths actually work to create the magic behind the curtain. </p>"},{"location":"DSP/algorithms/dft_vs_fft/#through-my-first-career-and-beyond","title":"Through my first career, and beyond.","text":"<p>I had to make use of it during my time working with 4G LTE layer 1 and 2. THe OFDMA frames decoding needed the iFFT and then ultimately to feed it to perform cellsearch. Here optimization on the FFT was not prioritized, but the fast implementation and system level integration were more pivotal to see the cellsearch working against the Matlab model in an actual FPGA hardware. Fun ways to learn about lots of topics, looking back. Then it came back to me as a task, this time to  implement a parameterizable, scalable and adaptable fixed point implementation targetting different signal processing chains in an ASIC. The efficiency, and memory footprint were paramount. To implement it as toolkit that supports varying lengths of FFT to be deployed, has some challenges when a single memory was used to store the source and target of the FFT butterfly stages.</p> <p>In this post, lets take a step toward understanding DFT and then dive a bit in to the FFT. Compare what changes and how it made the algorithm ubiquitous. </p>"},{"location":"DSP/algorithms/dft_vs_fft/#1-the-mathematical-foundation","title":"1. The Mathematical Foundation","text":"<p>The Discrete Fourier Transform (DFT) converts a sequence of \\(N\\) complex numbers into another sequence of \\(N\\) complex numbers in the frequency domain.</p>"},{"location":"DSP/algorithms/dft_vs_fft/#the-dft-formula","title":"The DFT Formula","text":"<p>For each frequency bin \\(k\\), the calculation is: $\\(X[k] = \\sum_{n=0}^{N-1} x[n] \\cdot e^{-j\\frac{2\\pi}{N}kn}\\)$</p>"},{"location":"DSP/algorithms/dft_vs_fft/#the-complexity-problem","title":"The Complexity Problem","text":"<p>To compute a full \\(N\\)-point DFT: 1. We calculate \\(N\\) frequency bins (\\(k=0\\) to \\(N-1\\)). 2. For each bin, we perform \\(N\\) complex multiplications and \\(N-1\\) complex additions. 3. This results in \\(O(N^2)\\) total operations.</p>"},{"location":"DSP/algorithms/dft_vs_fft/#2-the-fft-divide-and-conquer","title":"2. The FFT \"Divide and Conquer\"","text":"<p>The Fast Fourier Transform (FFT), specifically the Radix-2 Cooley-Tukey algorithm, reduces this complexity by splitting the DFT into even and odd indices recursively. How does this actually work. and Why ? By splitting the input sequence into even indices (\\(2n\\)) and odd indices (\\(2n+1\\)), we can rewrite the DFT summation as: $\\(X[k] = \\sum_{n=0}^{N/2-1} x[2n]e^{-j\\frac{2\\pi}{N}k(2n)} + \\sum_{n=0}^{N/2-1} x[2n+1]e^{-j\\frac{2\\pi}{N}k(2n+1)}\\)$ After some algebraic manipulation and using the Twiddle Factor \\(W_N^k = e^{-j\\frac{2\\pi}{N}k}\\), we arrive at the two equations that define the FFT Butterfly. These equations allow us to calculate two frequency outputs simultaneously from the even (\\(E[k]\\)) and odd (\\(O[k]\\)) sub-sequences: $\\(X[k] = E[k] + W_N^k O[k]\\)$</p> \\[X[k + N/2] = E[k] - W_N^k O[k]\\] <p>The \"magic\" that allows the second half of the spectrum (\\(X[k + N/2]\\)) to be calculated with a simple subtraction is the symmetry of the twiddle factors:</p> \\[W_N^{k + \\frac{N}{2}} = -W_N^k\\] <p>If you want to find X[k] for N=8:</p> <pre><code>You split your 8 samples into 4 even and 4 odd indices.\n\nYou run a 4-point FFT on the even samples to get E[k].\n\nYou run a 4-point FFT on the odd samples to get O[k].\n\nYou combine them using the Butterfly:\n</code></pre> <p>$\\(X[k] = E[k] + W_N^k.\u200bO[k]\\)$.</p> <p>But it doesn't stop there. To find that 4-point FFT, the algorithm splits that into two 2-point FFTs. And the 2-point FFT is split into 1-point FFTs.</p> <pre><code>Note: A 1-point FFT is the easiest math in the world: the DFT of a single sample is just the sample itself! X[0]=x[0].\n</code></pre>"},{"location":"DSP/algorithms/dft_vs_fft/#visualizing-the-split-n8","title":"Visualizing the Split (\\(N=8\\))","text":"<p>To process an 8-point signal, we decompose it until we reach 2-point butterflies:</p> <ol> <li>Stage 1: Split <code>[x0, x1, x2, x3, x4, x5, x6, x7]</code> into Even <code>[x0, x2, x4, x6]</code> and Odd <code>[x1, x3, x5, x7]</code>.</li> <li>Stage 2: Split the Even group into <code>[x0, x4]</code> and <code>[x2, x6]</code> and the Odd group into <code>[x1, x5]</code> and <code>[x3, x7]</code></li> <li>Stage 3: The 2-point Butterfly operates on these pairs.</li> </ol> <p>The 8 Point FFT, as it tickles down the stages. You could see the sequence gets a different order, with indices 000, 100, 010, 110, 001, 101, 011, 111. If you look at it a few times, you would see that it is just bit reversed at the indices.</p>"},{"location":"DSP/algorithms/dft_vs_fft/#the-butterfly-operation","title":"The Butterfly Operation","text":"<p>By exploiting the symmetry of the twiddle factors (\\(e^{-j...}\\)), we reuse intermediate results. This reduces the complexity to: $\\(\\text{Complexity} = O(N \\log_2 N)\\)$</p> N Samples DFT (\\(N^2\\)) FFT (\\(N \\log_2 N\\)) Speedup Factor 64 4,096 384 ~10x 1024 1,048,576 10,240 ~102x 4096 16,777,216 49,152 ~341x"},{"location":"DSP/algorithms/dft_vs_fft/#3-python-demonstration","title":"3. Python Demonstration","text":"<p>Below is a script to visualize the massive performance gap as \\(N\\) increases.</p> <pre><code>import numpy as np\nimport time\nimport matplotlib.pyplot as plt\n\ndef manual_dft(x):\n    N = len(x)\n    n = np.arange(N)\n    k = n.reshape((N, 1))\n    e = np.exp(-2j * np.pi * k * n / N)\n    return np.dot(e, x)\n\nsizes = [64, 128, 256, 512, 1024]\ndft_times = []\nfft_times = []\n\nfor N in sizes:\n    # Generate random signal\n    x = np.random.random(N)\n\n    # Time DFT\n    start = time.time()\n    manual_dft(x)\n    dft_times.append(time.time() - start)\n\n    # Time FFT\n    start = time.time()\n    np.fft.fft(x)\n    fft_times.append(time.time() - start)\n\nprint(f\"For N=1024, FFT is {dft_times[-1]/fft_times[-1]:.2f}x faster!\")\n</code></pre>"},{"location":"books/books/","title":"\ud83d\udcda Technical Reading List","text":"<p>\"Every Journey of thousand miles starts with a single step.\" Enjoy each step, be aware and intentional. Rushing yields no worth.</p> <p>This file serves as my library and progress tracker for mastering DSP, FPGA, and ASIC design.</p>"},{"location":"books/books/#currently-reading","title":"\ud83d\udcd6 Currently Reading","text":"Book Title Author Topic Progress Digital Signal Processing Proakis &amp; Manolakis DSP Fundamentals \u23f3 Chapter 3 Digital Design and Computer Architecture Harris &amp; Harris FPGA/ASIC \ud83d\udcd6 Chapter 1"},{"location":"books/books/#completed","title":"\ud83c\udfc1 Completed","text":"Book Title Date Finished Rating Key Takeaway The Pragmatic Programmer 2024-12-20 \u2b50\u2b50\u2b50\u2b50\u2b50 The story you tell yourself becomes the reality you live in."},{"location":"books/books/#wishlist-future-study","title":"\u23f3 Wishlist &amp; Future Study","text":"<ul> <li>[ ] Computer Architecture: A Quantitative Approach (Hennessy &amp; Patterson)</li> <li>[ ] CMOS VLSI Design: A Circuits and Systems Perspective (Weste &amp; Harris)</li> <li>[ ] Verilog HDL: A Guide to Digital Design and Synthesis (Samir Palnitkar)</li> </ul> <p>Patience, and relentless effort until everything moves frictionless.</p>"},{"location":"python/fixed_point_dsp/fft_reference_model/","title":"FFT Reference Model (Floating-Point)","text":"<p>Before moving to Fixed-Point ASIC implementation, it is important to have a reference model to test out the concept and act as a scoreboard in the testbench. For that purpose, it is crucial to have a floating-point reference model.</p> <p>We will use a bottom-up approach here. Getting the basic building blocks built first, tested, and the concept understood is a good way to proceed.</p>"},{"location":"python/fixed_point_dsp/fft_reference_model/#key-sub-blocks","title":"Key Sub-Blocks","text":"<ul> <li> <p>Bit Reversal for Indices and a RAM to store the data.     This has to be done either at the input level or the output level of the FFT. A RAM to mimic the hardware is a good idea here.</p> </li> <li> <p>Butterfly Unit     For performing FFT, one of the basic blocks is a FFT butterfly. To keep things simple, let's focus on building the FFT with a Radix-2 butterfly. The Butterfly needs to perform complex multiplication operations.</p> </li> <li> <p>FFT Stages and Data Feeding     The butterfly \"spans its wings\" based on the FFT stage. FFT relies on splitting an \\(N\\)-point FFT to \\(N/2\\)-point FFT of even and odd indices and making use of the twiddle factor symmetry. This is basically controlling the data flow to the butterfly and controlling the stages.</p> </li> <li> <p>FFT twiddle factor LUT     The LUT would be used to generate the twiddle factor which is needed for each stage of the FFT.</p> </li> </ul>"},{"location":"python/fixed_point_dsp/fft_reference_model/#1-the-butterfly-hardware-block","title":"1. The Butterfly \"Hardware\" Block","text":"<p>In a physical ASIC, the butterfly is a logic cluster of 4 multipliers and 6 adders.</p> \\[X[k] = E[k] + W_N^k O[k]\\] \\[X[k + N/2] = E[k] - W_N^k O[k]\\] <p>By feeding \\(E[k]\\) and \\(O[k]\\) terms to the butterfly, one could compute \\(X[k]\\) and \\(X[k + N/2]\\). This involves two complex multipliers and two complex adders.</p> <p>The complex multiplication typically needs 4 multiplications, but this can be reduced to 3 multiplications by using the Gauss multiplication method.</p>"},{"location":"python/fixed_point_dsp/fft_reference_model/#11-gauss-complex-multiplication","title":"1.1 Gauss Complex Multiplication","text":"<p>Step 1: The \"Overlap\" Term Let's create a common multiplication that uses both real and imaginary parts of our numbers. We will call it \\(k_1\\):</p> \\[k_1 = C \\cdot (A + B)\\] <p>If we expand this, we get: $\\(k_1 = AC + BC\\)$</p> <p>Notice that \\(AC\\) is part of our desired Real result, and \\(BC\\) is part of our desired Imaginary result.</p> <p>Step 2: Isolating the Real Part We want \\(AC - BD\\). We already have \\(AC + BC\\) from \\(k_1\\). To get rid of that \\(+BC\\) and turn it into \\(-BD\\), we need another multiplication. Let's try to find a term that involves \\(B\\):</p> \\[k_3 = B \\cdot (C + D) = BC + BD\\] <p>Now, look what happens if we subtract \\(k_3\\) from \\(k_1\\): $\\(k_1 - k_3 = (AC + BC) - (BC + BD)\\)$ $\\(k_1 - k_3 = AC - BD\\)$</p> <p>This is exactly our Real Part!</p> <p>Step 3: Isolating the Imaginary Part We want \\(AD + BC\\). We already have \\(AC + BC\\) from \\(k_1\\). To get rid of the \\(+AC\\) and turn it into \\(+AD\\), we need a term that involves \\(A\\):</p> \\[k_2 = A \\cdot (D - C) = AD - AC\\] <p>Now, look what happens if we add \\(k_1\\) and \\(k_2\\): $\\(k_1 + k_2 = (AC + BC) + (AD - AC)\\)$ $\\(k_1 + k_2 = BC + AD\\)$</p> <p>This is exactly our Imaginary Part!</p>"},{"location":"python/fixed_point_dsp/fft_reference_model/#hardware-requirement-summary","title":"Hardware Requirement Summary","text":"Intermediate Operation Hardware Requirement \\(k_1\\) \\(C \\cdot (A + B)\\) 1 Mult, 1 Add \\(k_2\\) \\(A \\cdot (D - C)\\) 1 Mult, 1 Sub \\(k_3\\) \\(B \\cdot (C + D)\\) 1 Mult, 1 Add Real Result \\(k_1 - k_3\\) 1 Sub Imag Result \\(k_1 + k_2\\) 1 Add"},{"location":"python/fixed_point_dsp/fft_reference_model/#python-implementation","title":"Python Implementation","text":"<pre><code>def multiplier_3mul(A, B, C, D):\n    \"\"\"\n    Computes (A + jB) * (C + jD) using Gauss's 3-multiplier method.\n    \"\"\"\n    # Pre-additions (Cheap in Silicon)\n    sum_AB = A + B\n    diff_DC = D - C\n    sum_CD = C + D\n\n    # 3 Multiplications (Expensive in Silicon)\n    k1 = C * sum_AB\n    k2 = A * diff_DC\n    k3 = B * sum_CD\n\n    # Final assembly\n    real_out = k1 - k3\n    imag_out = k1 + k2\n    return real_out, imag_out\n\ndef butterfly_unit(A_re, A_im, B_re, B_im, W_re, W_im):\n    # Twiddle product: (B_re + jB_im) * (W_re + jW_im)\n    twid_re, twid_im = multiplier_3mul(B_re, B_im, W_re, W_im)\n\n    # Sum/Diff stage\n    up_re, up_im = A_re + twid_re, A_im + twid_im\n    low_re, low_im = A_re - twid_re, A_im - twid_im\n    return up_re, up_im, low_re, low_im\n</code></pre>"},{"location":"python/fixed_point_dsp/fft_reference_model/#2-bit-reversal-for-indices-and-a-ram-to-store-the-data","title":"2. Bit Reversal for Indices and a RAM to store the data.","text":"<p>The data as it moves across the butterfly stages, get shuffled due to sorting them by even and odd indices as shown in the figure. so to revert back the order of the FFT, a bit reversal of the indices are needed. This can be done either at the start or at the end of the FFT.</p> <p>since we are going for a radix 2 butterfly design, two instances of data needs to be read simultaneously. To solve this problem, we could add two single port RAM with half the size. </p> <p>Following that train of thoughts. One way of partitioning the data, would be move the odd indices to One RAM and the viceversa. This would work for stage 1, but for stage 2 the two reads will end up from the same  RAM. Oops.</p> <p>The solution is simple. </p> <p>For Stage 1, the data read spans by changing the LSB bit. For stage 2, the data read spans by changing the 2nd LSB bit. For stage 3, the data read spans by changing the 3rd LSB bit. </p> <p>So we could use XOR based banking. Which is to use the parity of the XOR sum of all the bits of the address to resolve the banking..</p>"},{"location":"python/fixed_point_dsp/fft_reference_model/#21-python-implementation-of-the-ram","title":"2.1 python implementation of the RAM.","text":"<pre><code>import math\n\nclass XOR_RAM:\n    \"\"\"\n    Dual-Bank RAM with Parity Banking &amp; Dense Addressing.\n    \"\"\"\n    def __init__(self, size):\n        self.depth = size // 2\n        self.bank0 = [0] * self.depth  # Even Parity Bank\n        self.bank1 = [0] * self.depth  # Odd Parity Bank\n\n    def _translate(self, logical_addr):\n        \"\"\"\n        Hardware Decoder:\n        - Bank = XOR Sum of bits (Parity)\n        - Row  = Logical Address &gt;&gt; 1\n        \"\"\"\n        bank = bin(logical_addr).count('1') % 2\n        row  = logical_addr &gt;&gt; 1\n        return bank, row\n\n    def check_access(self, addr_A, addr_B):\n        \"\"\"\n        Simulates a simultaneous read. Returns details for printing.\n        Raises ValueError if a collision occurs.\n        \"\"\"\n        bank_A, row_A = self._translate(addr_A)\n        bank_B, row_B = self._translate(addr_B)\n\n        if bank_A == bank_B:\n            raise ValueError(f\"CONFLICT! {addr_A} &amp; {addr_B} -&gt; Both Bank {bank_A}\")\n\n        return (bank_A, row_A), (bank_B, row_B)\n\ndef verify_fft_8_banking():\n    N = 8\n    stages = int(math.log2(N))\n    ram = XOR_RAM(N)\n\n    print(f\"{'Stage':&lt;6} | {'Pair (Logical)':&lt;16} | {'Bin A':&lt;6} {'Bin B':&lt;6} | {'Bank A':&lt;7} {'Bank B':&lt;7} | {'Result'}\")\n    print(\"-\" * 80)\n\n    # Simulate FFT AGU Loops\n    for s in range(1, stages + 1):\n        span = 2**(s - 1)\n        m = 2**s\n\n        for group in range(0, N, m):\n            for k in range(span):\n                idx_A = group + k\n                idx_B = group + k + span\n\n                try:\n                    (bA, rA), (bB, rB) = ram.check_access(idx_A, idx_B)\n\n                    # Formatting for clean output\n                    bin_A = f\"{idx_A:03b}\"\n                    bin_B = f\"{idx_B:03b}\"\n                    status = \"\u2705 OK\"\n\n                    print(f\"Stg {s:&lt;2} | ({idx_A}, {idx_B}){' ':&lt;8} | {bin_A:&lt;6} {bin_B:&lt;6} | {bA:&lt;7} {bB:&lt;7} | {status}\")\n\n                except ValueError as e:\n                    print(f\"Stg {s:&lt;2} | ({idx_A}, {idx_B}) - \u274c FAIL: {e}\")\n\nif __name__ == \"__main__\":\n    verify_fft_8_banking()\n</code></pre>"},{"location":"python/fixed_point_dsp/fft_reference_model/#22-conflict-free-memory-xor-strategy-addressing","title":"2.2 Conflict-Free Memory: XOR Strategy &amp; Addressing","text":"<p>To solve the conflict in Stage 2, we use Parity Banking. This ensures that any two addresses differing by 1 bit (Hamming distance 1) always land in different banks.</p> <p>Running the python verification generates this table. And we can validate that there is no memory access conflict with this approach. <pre><code>Stage  | Pair (Logical)   | Bin A  Bin B  | Bank A  Bank B  | Result\n--------------------------------------------------------------------------------\nStg 1  | (0, 1)         | 000    001    | 0       1       | \u2705 OK\nStg 1  | (2, 3)         | 010    011    | 1       0       | \u2705 OK\nStg 1  | (4, 5)         | 100    101    | 1       0       | \u2705 OK\nStg 1  | (6, 7)         | 110    111    | 0       1       | \u2705 OK\nStg 2  | (0, 2)         | 000    010    | 0       1       | \u2705 OK\nStg 2  | (1, 3)         | 001    011    | 1       0       | \u2705 OK\nStg 2  | (4, 6)         | 100    110    | 1       0       | \u2705 OK\nStg 2  | (5, 7)         | 101    111    | 0       1       | \u2705 OK\nStg 3  | (0, 4)         | 000    100    | 0       1       | \u2705 OK\nStg 3  | (1, 5)         | 001    101    | 1       0       | \u2705 OK\nStg 3  | (2, 6)         | 010    110    | 1       0       | \u2705 OK\nStg 3  | (3, 7)         | 011    111    | 0       1       | \u2705 OK\n</code></pre></p>"},{"location":"python/fixed_point_dsp/fft_reference_model/#3-twiddle-factor-architecture-rom-optimization","title":"3. Twiddle Factor Architecture (ROM Optimization)","text":"<p>In an ASIC implementation, calculating sines and cosines on the fly is computationally expensive, and storing a full table for every angle \\(0 \\dots 2\\pi\\) is wasteful. </p> <p>We use a \"Hardware-Friendly\" approach relying on Quarter-Wave Symmetry to reduce storage by 75% and Bit-Shifting to reuse a single Master Table across all FFT stages.</p>"},{"location":"python/fixed_point_dsp/fft_reference_model/#31-quarter-wave-optimization","title":"3.1 Quarter-Wave Optimization","text":"<p>We only store the Cosine values for the first quadrant (\\(0^\\circ\\) to \\(90^\\circ\\)). * Storage Range: \\(0 \\le \\theta \\le \\pi/2\\) (Indices \\(0 \\dots N/4\\)). * Real Part (Cos): Direct lookup from the table. * Imaginary Part (Sin): Derived using the trigonometric identity:   $\\(\\sin(\\theta) = \\cos(90^\\circ - \\theta)\\)$</p> <p>Since we store Cosine, we can find the Sine of any angle \\(k\\) by reading the table backwards from the \\(90^\\circ\\) mark (\\(N/4 - k\\)).</p>"},{"location":"python/fixed_point_dsp/fft_reference_model/#32-quadrant-mapping-logic-the-mirror","title":"3.2 Quadrant Mapping Logic (The Mirror)","text":"<p>Standard FFTs require angles up to \\(180^\\circ\\) (Quadrant 2). Since our table stops at \\(90^\\circ\\), we use geometric mirroring.</p> <ul> <li>Mirroring: An angle in Q2 (e.g., \\(135^\\circ\\)) uses the same table value as its mirror in Q1 (\\(45^\\circ\\)), but with a sign change for the Cosine.</li> <li>The Formula: <code>Index_Q1 = (N/2) - Index_Q2</code></li> </ul> Quadrant Angle Range Lookup Index Real Sign (Cos) Imag Sign (\\(-j\\sin\\)) Q1 \\(0 \\dots 90^\\circ\\) \\(k\\) Positive (\\(+\\)) Negative (\\(-\\)) Q2 \\(90 \\dots 180^\\circ\\) \\(N/2 - k\\) Negative (\\(-\\)) Negative (\\(-\\)) <p>&gt; Note: The Imaginary sign is negative in both quadrants because the FFT definition is \\(W = \\cos(\\theta) - j\\sin(\\theta)\\). Since \\(\\sin(\\theta)\\) is positive in both Q1 and Q2, the term \\(-j\\sin(\\theta)\\) remains negative.</p>"},{"location":"python/fixed_point_dsp/fft_reference_model/#33-hardware-address-decoding-bit-shifting","title":"3.3 Hardware Address Decoding (Bit-Shifting)","text":"<p>Earlier FFT stages need \"lower resolution\" angles. Instead of creating separate tables for Stage 1, Stage 2, etc., we use the Master Table (Stage \\(M\\)) for everything.</p> <p>We simply left-shift the address to \"skip\" intermediate values.</p> <ul> <li>Formula: <code>ROM_Addr = k &lt;&lt; (Max_Stages - Current_Stage)</code></li> </ul> Stage Butterfly Index \\(k\\) Shift Effective Angle 3 (Full) 0, 1, 2, 3 0 \\(0, 1, 2, 3\\) (\\(0^\\circ, 45^\\circ \\dots\\)) 2 (Half) 0, 1 1 \\(0, 2\\) (\\(0^\\circ, 90^\\circ\\)) 1 (Low) 0 2 \\(0\\) (\\(0^\\circ\\))"},{"location":"python/fixed_point_dsp/fft_reference_model/#34-python-implementation-twiddlerom","title":"3.4 Python Implementation: <code>TwiddleROM</code>","text":"<p>This class models the hardware ROM, the bit-shifting AGU, and the Quadrant Mapping logic.</p> <pre><code>import math\n\nclass TwiddleROM:\n    \"\"\"\n    Hardware-Optimized Twiddle Factor Generator.\n    - Stores only Quarter-Wave (0 to 90 degrees).\n    - Uses Quadrant Mirroring for angles &gt; 90 degrees.\n    \"\"\"\n    def __init__(self, N):\n        self.N = N\n        self.quarter_size = N // 4\n\n        # 1. Generate the Quarter-Wave LUT (Cosine only)\n        # Size: (N/4) + 1 entries.\n        self.lut = []\n        print(f\"--- Generating ROM (Size: {self.quarter_size + 1}) ---\")\n        for i in range(self.quarter_size + 1):\n            angle = 2 * math.pi * i / N\n            val = math.cos(angle)\n            self.lut.append(val)\n\n    def get_twiddle(self, stage, k):\n        \"\"\"\n        Retrieves W = e^(-j 2pi k / 2^stage) using Bit-Shifting &amp; Mirroring.\n        \"\"\"\n        # 1. Bit-Shift Strategy: Map current stage 'k' to Master ROM index\n        total_stages = int(math.log2(self.N))\n        shift = total_stages - stage\n        master_idx = k &lt;&lt; shift\n\n        # 2. Quadrant Logic\n        if master_idx &gt; self.quarter_size:\n            # Quadrant 2: Mirroring Logic\n            # Map 135 deg -&gt; 45 deg via (180 - 135)\n            lut_idx = (self.N // 2) - master_idx\n            sign_re = -1  # Cosine is Negative in Q2\n            sign_im = -1  # Sine is Positive, so -j*sin is Negative\n        else:\n            # Quadrant 1: Direct Mapping\n            lut_idx = master_idx\n            sign_re = 1   # Cosine is Positive in Q1\n            sign_im = -1  # -j*sin is Negative\n\n        # 3. Fetch Real Part (Cosine)\n        re = self.lut[lut_idx] * sign_re\n\n        # 4. Fetch Imag Part (Sine derived from Cosine)\n        # sin(theta) = cos(90 - theta) -&gt; Table[Max - Index]\n        im_lut_idx = self.quarter_size - lut_idx\n        im = self.lut[im_lut_idx] * sign_im\n\n        return re, im\n</code></pre>"},{"location":"python/fixed_point_dsp/quantization_basics/","title":"Fixed-Point Quantization","text":""},{"location":"python/fixed_point_dsp/quantization_basics/#1-objective","title":"1. \ud83c\udfaf Objective","text":"<p>To understand how to convert floating-point signals into fixed-point representations suitable for FPGA/ASIC implementation, and to analyze the resulting quantization noise. As a beginning and to familiarize with the tools lets focus on Rounding and Truncation.</p>"},{"location":"python/fixed_point_dsp/quantization_basics/#2-background","title":"2. \ud83d\udca1Background","text":""},{"location":"python/fixed_point_dsp/quantization_basics/#21-concept-the-q_mn-format","title":"2.1  Concept: The \\(Q_{m.n}\\) Format","text":"<p>In hardware, we represent numbers using a fixed number of bits: - Total Bits (\\(W\\)): The word length. - Integer Bits (\\(m\\)): Bits for the integer part (including sign bit). - Fractional Bits (\\(n\\)): Bits for the precision.</p> <p>The formula to convert a float to fixed-point is:</p> \\[Fixed = \\text{round}(Float \\times 2^n)\\]"},{"location":"python/fixed_point_dsp/quantization_basics/#22-theoretical-comparison","title":"2.2 Theoretical Comparison","text":"Method Hardware Cost Statistical Bias Truncation Zero (just drop LSBs) High (Always shifts the mean negative) Rounding Moderate (requires an adder) Low (Mean error stays near zero)"},{"location":"python/fixed_point_dsp/quantization_basics/#3-visualizing-the-error","title":"3. Visualizing the Error","text":"<p>Below are the results of my Python simulation comparing a high-precision sine wave against its quantized versions. Consider Q(s=1, w=8, f=2), and an input of Sine wave is generated and then converted to Fixed point data by using rounding and then truncation. The error distribution is shown in the Fig 3.1</p>"},{"location":"python/fixed_point_dsp/quantization_basics/#error-distribution","title":"Error Distribution","text":""},{"location":"python/fixed_point_dsp/quantization_basics/#observations","title":"Observations:","text":"<ul> <li>Truncation Error: The error is always between \\((-1, 0]\\). This introduces a DC Offset into the FFT bins, which can be catastrophic for weak signal detection.</li> <li>Rounding Error: The error is centered around \\(0\\) (between \\([-0.5, 0.5]\\)). While it costs slightly more logic, it preserves the dynamic range and prevents DC bias.</li> </ul>"},{"location":"python/fixed_point_dsp/quantization_basics/#python-implementation","title":"\ud83d\udc0d Python Implementation","text":"<p>This script demonstrates how to quantize a sine wave. Compare rounding versus truncation.</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom numfi import numfi\n\n# 1. Setup Time and Signal (Use linspace for safety)\nfs = 1000\nduration = 0.1\nN_samples = int(fs * duration)\nt = np.linspace(0, duration, N_samples, endpoint=False) \n\nf_signal = 20\nx = np.sin(2 * np.pi * f_signal * t)\n\n# 2. Fixed-point quantization\ny_floor = numfi(x, s=1, w=8, f=2, RoundingMethod='Floor')\ny_round = numfi(x, s=1, w=8, f=2, RoundingMethod='Nearest')\n\n# 3. Calculate Errors\n# np.broadcast_to is used to make sure that the y_floor.double is the same size as x.\ny_floor_vals = np.broadcast_to(y_floor.double, x.shape)\ny_round_vals = np.broadcast_to(y_round.double, x.shape)\n\nerr_floor = y_floor_vals - x\nerr_round = y_round_vals - x\n\n# 4. Plotting\nplt.figure(figsize=(12, 8))\n\nplt.subplot(3, 1, 1)\nplt.plot(t, err_floor, label='Floor Error')\nplt.axhline(np.mean(err_floor), color='red', linestyle='--',\n            label=f'Mean: {np.mean(err_floor):.4f}')\nplt.title(\"Floor Error (Bias is visible)\")\nplt.legend(loc='upper right')\nplt.grid(True)\n\nplt.subplot(3, 1, 2)\nplt.plot(t, err_round, label='Round Error', color='orange')\nplt.axhline(np.mean(err_round), color='red', linestyle='--',\n            label=f'Mean: {np.mean(err_round):.4f}')\nplt.title(\"Round Error (Centered on Zero)\")\nplt.legend(loc='upper right')\nplt.grid(True)\n\nplt.subplot(3, 1, 3)\nplt.plot(t, x, label='Original signal', color='black', alpha=0.3)\nplt.step(t, y_floor_vals, label='Floor (Truncated)', where='post', linestyle='--')\nplt.step(t, y_round_vals, label='Round (Nearest)', where='post')\n\nplt.title(\"Signal Comparison: Original vs Fixed Point\")\nplt.xlabel(\"Time (s)\")\nplt.legend(loc='upper right')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"til/","title":"Today I Learned (TIL)","text":"<p>A digital log of small snippets and engineering realizations.</p>"},{"location":"til/#december-2025","title":"\ud83d\udcc5 December 2025","text":""},{"location":"til/#dec-26-reference-models-git","title":"Dec 26: Reference Models &amp; Git","text":"<p>Tags: #LinuxKernel #DSP #Python </p> Key Realizations"},{"location":"til/#dec-26-reference-models-git_1","title":"Dec 26: Reference Models &amp; Git","text":"<p>Tags: #DSP #Python #Git #mkdoc     * Linux Kernel and Intel wifi driver issues: HAd to turn the pcie_aspm=off + iwlwifi power_save=0\\(.     * **FFT twiddle factor generation:** HOw to generate the complete sine and consine table from a quadrant of just cosine table.\\).</p> Key Realizations <ul> <li>FFT Span Logic: Stage \\(S\\) uses a stride of \\(2^{S-1}\\).</li> <li>Git Safety: <code>git rm --cached</code> is the best way to fix a messy repo.</li> <li>Mkdoc :  It is good to have a local Mkdoc development env. Pip install mkdoc &amp; then mkdoc serve.</li> <li>Comparing Fixed point data and real number : Using Numfi library to generate fixed point data. </li> </ul> <p>Read full FFT Reference Model \u2192</p>"},{"location":"til/#dec-25-project-kickoff","title":"Dec 25: Project Kickoff","text":"<p>Tags: #Documentation #FFT</p> Initialization <ul> <li>MkDocs environment established.</li> <li>Dived into FFT and made the first post about it.</li> </ul>"},{"location":"til/#technical-snippets","title":"\ud83d\udee0\ufe0f Technical Snippets","text":""},{"location":"til/#python-environment-management","title":"\ud83d\udc0d Python Environment Management","text":"<p>When starting a new DSP project, isolate dependencies to avoid version conflicts.</p> Command Action <code>python -m venv dsp</code> Create the virtual environment <code>source dsp/bin/activate</code> Activate (Linux/macOS) <code>dsp\\Scripts\\activate</code> Activate (Windows) <code>pip install numpy matplotlib</code> Install core DSP library stack"},{"location":"til/#git-removing-tracked-folders","title":"\ud83d\udee1\ufe0f Git: Removing Tracked Folders","text":"<p>If you accidentally commit a folder (like <code>dsp/</code> or <code>__pycache__</code>), use this sequence to clean the repo without deleting your local files.</p> <pre><code># 1. Remove from Git's tracking (but keep files on disk)\ngit rm -r --cached dsp/\n\n# 2. Add to your .gitignore to prevent future tracking\necho \"dsp/\" &gt;&gt; .gitignore\n\n# 3. Commit the change\ngit add .gitignore\ngit commit -m \"chore: stop tracking virtual environment\"\n</code></pre>"}]}